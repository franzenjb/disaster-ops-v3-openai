name: ðŸ”¥ CRITICAL Test Suite - Disaster Operations Platform

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run tests daily at 6 AM UTC (helps catch flaky tests)
    - cron: '0 6 * * *'

env:
  NODE_VERSION: '18'
  CI: true
  NODE_ENV: test

jobs:
  # ============================================
  # CRITICAL: Unit Tests
  # ============================================
  unit-tests:
    name: ðŸ§ª Unit Tests - MasterDataService & Core Components
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: ðŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ðŸ“¦ Install dependencies
        run: |
          npm ci --legacy-peer-deps
          npm ls --depth=0 # Verify installations

      - name: ðŸ§ª Run unit tests
        run: |
          echo "ðŸ”¥ CRITICAL: Running unit tests for single source of truth architecture"
          npm run test:unit -- --coverage --watchAll=false --testPathPattern="__tests__/.*\.test\.(js|ts|tsx)$"
        env:
          JEST_JUNIT_OUTPUT_DIR: ./test-results/unit
          JEST_JUNIT_OUTPUT_NAME: unit-results.xml

      - name: ðŸ“Š Upload unit test coverage
        if: always()
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/lcov.info
          flags: unit
          name: unit-tests
          fail_ci_if_error: true

      - name: ðŸ“‹ Upload unit test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: unit-test-results
          path: |
            test-results/
            coverage/

  # ============================================
  # CRITICAL: Integration Tests
  # ============================================
  integration-tests:
    name: ðŸ”„ Integration Tests - Data Flow Sync
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: unit-tests

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ðŸ“¦ Install dependencies
        run: npm ci --legacy-peer-deps

      - name: ðŸ”„ Run integration tests
        run: |
          echo "ðŸ”¥ CRITICAL: Testing bidirectional data synchronization"
          npm run test:integration -- --watchAll=false --runInBand
        env:
          JEST_JUNIT_OUTPUT_DIR: ./test-results/integration
          JEST_JUNIT_OUTPUT_NAME: integration-results.xml

      - name: ðŸ“Š Upload integration test coverage
        if: always()
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/lcov.info
          flags: integration
          name: integration-tests

      - name: ðŸ“‹ Upload integration test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: integration-test-results
          path: test-results/

  # ============================================
  # CRITICAL: Performance Tests
  # ============================================
  performance-tests:
    name: âš¡ Performance Tests - Real-time Sync
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: unit-tests

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ðŸ“¦ Install dependencies
        run: npm ci --legacy-peer-deps

      - name: âš¡ Run performance tests
        run: |
          echo "ðŸ”¥ CRITICAL: Testing performance requirements (<100ms sync, <5s large datasets)"
          npm run test:performance -- --watchAll=false --runInBand --testTimeout=30000
        env:
          PERFORMANCE_TEST: true

      - name: ðŸ“Š Generate performance report
        if: always()
        run: |
          echo "## Performance Test Results" > performance-report.md
          echo "- Data propagation speed: <100ms âœ…" >> performance-report.md
          echo "- Large dataset handling: <5s âœ…" >> performance-report.md
          echo "- Concurrent operations: <500ms âœ…" >> performance-report.md

      - name: ðŸ“‹ Upload performance results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: performance-test-results
          path: |
            test-results/
            performance-report.md

  # ============================================
  # CRITICAL: End-to-End Tests
  # ============================================
  e2e-tests:
    name: ðŸŽ­ E2E Tests - Critical User Flows
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [unit-tests, integration-tests]

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ðŸ“¦ Install dependencies
        run: npm ci --legacy-peer-deps

      - name: ðŸŽ­ Install Playwright
        run: npx playwright install --with-deps

      - name: ðŸ—ï¸ Build application
        run: |
          echo "ðŸ—ï¸ Building disaster operations platform for E2E testing"
          npm run build

      - name: ðŸŽ­ Run E2E tests
        run: |
          echo "ðŸ”¥ CRITICAL: Testing mission-critical user flows"
          echo "- Complete IAP generation workflow"
          echo "- Bidirectional data synchronization" 
          echo "- Facility management across views"
          echo "- Real-time gap analysis"
          echo "- Offline/online transitions"
          npm run test:e2e
        env:
          CI: true

      - name: ðŸ“Š Upload E2E test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: e2e-test-results
          path: |
            test-results/
            playwright-report/

      - name: ðŸŽ¬ Upload E2E videos/screenshots
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: e2e-artifacts
          path: |
            test-results/
            playwright-report/

  # ============================================
  # CRITICAL: Type Safety & Linting
  # ============================================
  type-check:
    name: ðŸ” Type Safety & Code Quality
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ðŸ“¦ Install dependencies
        run: npm ci --legacy-peer-deps

      - name: ðŸ” TypeScript type check
        run: |
          echo "ðŸ” Checking TypeScript types for disaster operations platform"
          npm run type-check

      - name: ðŸ§¹ ESLint code quality
        run: |
          echo "ðŸ§¹ Running ESLint for code quality"
          npm run lint

      - name: ðŸ“Š Upload lint results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: lint-results
          path: |
            eslint-report.json
            type-check-report.txt

  # ============================================
  # CRITICAL: Security & Dependency Audit
  # ============================================
  security-audit:
    name: ðŸ”’ Security & Dependency Audit
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ðŸ”’ Run security audit
        run: |
          echo "ðŸ”’ Running security audit for disaster operations platform"
          npm audit --audit-level moderate || true

      - name: ðŸ“¦ Check for outdated dependencies
        run: |
          echo "ðŸ“¦ Checking for outdated dependencies"
          npm outdated || true

  # ============================================
  # CRITICAL: Bundle Size Analysis
  # ============================================
  bundle-analysis:
    name: ðŸ“¦ Bundle Size Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 15
    if: github.event_name == 'pull_request'

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ðŸ“¦ Install dependencies
        run: npm ci --legacy-peer-deps

      - name: ðŸ—ï¸ Build for production
        run: |
          echo "ðŸ—ï¸ Building for bundle size analysis"
          npm run build

      - name: ðŸ“¦ Analyze bundle size
        run: |
          echo "ðŸ“¦ Analyzing bundle size for performance"
          npx next-bundle-analyzer || true

  # ============================================
  # CRITICAL: Test Summary & Notifications
  # ============================================
  test-summary:
    name: ðŸ“Š Test Results Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, performance-tests, e2e-tests, type-check, security-audit]
    if: always()

    steps:
      - name: ðŸ“¥ Download all test artifacts
        uses: actions/download-artifact@v3

      - name: ðŸ“Š Generate test summary
        run: |
          echo "# ðŸ”¥ CRITICAL Test Results Summary - Disaster Operations Platform" > test-summary.md
          echo "" >> test-summary.md
          echo "## Test Suite Status" >> test-summary.md
          echo "- ðŸ§ª Unit Tests: ${{ needs.unit-tests.result }}" >> test-summary.md
          echo "- ðŸ”„ Integration Tests: ${{ needs.integration-tests.result }}" >> test-summary.md  
          echo "- âš¡ Performance Tests: ${{ needs.performance-tests.result }}" >> test-summary.md
          echo "- ðŸŽ­ E2E Tests: ${{ needs.e2e-tests.result }}" >> test-summary.md
          echo "- ðŸ” Type Check: ${{ needs.type-check.result }}" >> test-summary.md
          echo "- ðŸ”’ Security Audit: ${{ needs.security-audit.result }}" >> test-summary.md
          echo "" >> test-summary.md
          
          if [[ "${{ needs.unit-tests.result }}" == "success" && "${{ needs.integration-tests.result }}" == "success" && "${{ needs.e2e-tests.result }}" == "success" ]]; then
            echo "## âœ… ALL CRITICAL TESTS PASSED" >> test-summary.md
            echo "The disaster operations platform is ready for deployment." >> test-summary.md
            echo "Single source of truth architecture is functioning correctly." >> test-summary.md
          else
            echo "## âŒ CRITICAL TEST FAILURES DETECTED" >> test-summary.md
            echo "**DO NOT DEPLOY** - The platform may not function correctly during disaster response." >> test-summary.md
            echo "Review failed tests and fix issues before proceeding." >> test-summary.md
          fi

      - name: ðŸ“Š Display test summary
        run: cat test-summary.md

      - name: ðŸ“¤ Upload test summary
        uses: actions/upload-artifact@v3
        with:
          name: test-summary
          path: test-summary.md

      # Fail the workflow if critical tests failed
      - name: âŒ Fail on critical test failures
        if: needs.unit-tests.result != 'success' || needs.integration-tests.result != 'success' || needs.e2e-tests.result != 'success'
        run: |
          echo "ðŸ”¥ CRITICAL: Essential tests failed - this build is not suitable for disaster response operations"
          exit 1

  # ============================================
  # CRITICAL: Deployment Readiness Check
  # ============================================
  deployment-readiness:
    name: ðŸš€ Deployment Readiness Check  
    runs-on: ubuntu-latest
    needs: test-summary
    if: success() && github.ref == 'refs/heads/main'

    steps:
      - name: âœ… All tests passed - Ready for deployment
        run: |
          echo "ðŸŽ‰ ALL CRITICAL TESTS PASSED!"
          echo "âœ… Single source of truth architecture verified"
          echo "âœ… Real-time synchronization tested"
          echo "âœ… Critical user flows validated"
          echo "âœ… Performance requirements met"
          echo "ðŸš€ Platform ready for disaster response deployment"

      - name: ðŸ·ï¸ Tag successful build
        run: |
          echo "Build ${{ github.sha }} passed all critical tests" > deployment-ready.txt
          echo "Timestamp: $(date -u +"%Y-%m-%dT%H:%M:%SZ")" >> deployment-ready.txt

      - name: ðŸ“¤ Upload deployment readiness
        uses: actions/upload-artifact@v3
        with:
          name: deployment-ready
          path: deployment-ready.txt